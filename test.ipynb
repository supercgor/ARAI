{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "path = \"/Volumes/HEIU/data/bulkice_train.hdf5\"\n",
    "print(path)\n",
    "f = h5py.File(path, \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import AFMDataset\n",
    "path = \"/Volumes/HEIU/data/bulkice_train.hdf5\"\n",
    "\n",
    "dts = AFMDataset(path)\n",
    "fn, afm, label_type, label_pos = dts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(make_grid(afm.transpose(1,0)).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['T180_13015'].afm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import z_sampler\n",
    "z_sampler(10, 4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from dataset import transform as tf\n",
    "\n",
    "pics = torch.ones(1, 8, 100, 100) * 0.9\n",
    "pics[..., 50:, 0:50] = 0.1\n",
    "pics[..., :50, 50:] = 0.1\n",
    "\n",
    "transform = nn.Sequential(\n",
    "    tf.PixelShift(),\n",
    "    tf.Cutout(),\n",
    "    tf.ColorJitter(),\n",
    "    tf.Noisy(),\n",
    "    tf.Blur(),\n",
    ")\n",
    "t = time.time()\n",
    "for i in range(1):\n",
    "    pics = transform(pics)\n",
    "\n",
    "print(time.time() - t)\n",
    "\n",
    "\n",
    "T = torchvision.utils.make_grid(pics.transpose(1,0),pad_value = 0.5)\n",
    "plt.imshow(T.permute(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(100, 100)\n",
    "a[10:20, 10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.rand(100, 100, 3)\n",
    "b = torch.rand(100, 100) > 0.5\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.ones((50, 50, 5))\n",
    "c = torch.rand((50, 50, 5, 3))\n",
    "mask = a.nonzero()\n",
    "print(mask.T.shape)\n",
    "a[tuple(mask.T)]\n",
    "(c[tuple(mask.T)] + mask) / (50, 50, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import poscar\n",
    "box_cls = torch.randint(0, 3, (3, 50, 50), dtype=torch.long)\n",
    "box_off = torch.rand((3, 50, 50, 3))\n",
    "print(poscar.boxncls2pos_torch(box_cls, box_off))\n",
    "print(poscar.boxncls2pos_np(box_cls.numpy(), box_off.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.metrics import Analyser\n",
    "from utils import poscar\n",
    "from dataset import AFMDataset\n",
    "path = \"/Volumes/HEIU/data/bulkice_train.hdf5\"\n",
    "\n",
    "dts = AFMDataset(path)\n",
    "fn, afm, label_type, label_pos = dts[0]\n",
    "pred_types, pred_pos = poscar.targ2pred(label_type, label_pos)\n",
    "a = torch.jit.script(Analyser())\n",
    "pred_types = pred_types.unsqueeze(0).repeat((10, 1, 1, 1, 1))\n",
    "pred_pos  = pred_pos.unsqueeze(0).repeat((10, 1, 1, 1, 1))\n",
    "label_type = label_type.unsqueeze(0).repeat((10, 1, 1, 1))\n",
    "label_pos = label_pos.unsqueeze(0).repeat((10, 1, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "for i in range(1000):\n",
    "    a(pred_types, pred_pos, label_type, label_pos)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((100, 100, 3))\n",
    "mask = torch.nonzero(a, as_tuple=True)\n",
    "a[mask[0], mask[1], mask[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from utils.metrics import ConfusionMatrixCounter\n",
    "cm = torch.randint(0, 100, (1, 2, 1, 3)).numpy()\n",
    "t = time.time()\n",
    "ConfusionMatrixCounter._count(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import unet_onehot\n",
    "m = unet_onehot()\n",
    "img = torch.rand((1, 1, 10, 100, 100))\n",
    "m(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from utils.metrics import Analyser\n",
    "from utils import poscar\n",
    "from dataset import AFMDataset\n",
    "path = \"/Volumes/HEIU/data/bulkice_train.hdf5\"\n",
    "\n",
    "dts = AFMDataset(path)\n",
    "fn, afm, label_type, label_pos = dts[0]\n",
    "print(fn)\n",
    "typ, pos, _ = poscar.boxncls2pos_torch(label_type, label_pos)\n",
    "typ = typ.numpy()\n",
    "pos = pos.numpy()\n",
    "print(len(pos))\n",
    "pos2 = np.concatenate([pos[typ == i] for i in range(1,3)])\n",
    "poscar.save(\"test.poscar\", [3.0, 25.0, 25.0], ['O', 'H'], [48, 96], pos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = [\"1\", \"2\", \"3\"]\n",
    "np.array(a, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(\"9246.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def getWaterRotate(tag: np.ndarray, inv_ref: np.ndarray) -> np.ndarray:\n",
    "    O, H1, H2 = tag\n",
    "    H1, H2 = H1 - O, H2 - O\n",
    "    H1 = H1 / 0.9572\n",
    "    H2 = H2 / 0.9572\n",
    "    H3 = np.cross(H1, H2)\n",
    "    if H3[2] < 0:\n",
    "        tag[0] = H2\n",
    "        tag[1] = H1\n",
    "        tag[2] = -H3\n",
    "    else:\n",
    "        tag[0] = H1\n",
    "        tag[1] = H2\n",
    "        tag[2] = H3\n",
    "    return inv_ref @ tag\n",
    "\n",
    "ang = 104.52 / 180 * np.pi\n",
    "v = np.array([0, 0, 1])\n",
    "u = np.array([np.sin(ang), 0, np.cos(ang)])\n",
    "r = np.cross(v, u)\n",
    "ref = np.asarray([v, u, r])\n",
    "invref = np.linalg.inv(ref)\n",
    "\n",
    "pos = np.asarray([[6.20233009,  6.80328286,  0.71540000], [6.72382009,  6.43174286,  0.00390000], [5.46304009, 6.20268286,  0.81010000]])\n",
    "#pos = np.asarray([[14.10287009, 18.97821286,  0.47590000], [14.35087009, 19.79591286,  0.04450000], [13.24817009, 19.16231286,  0.86570000]])\n",
    "import time\n",
    "t = time.time()\n",
    "for i in range(1000):\n",
    "    R = getWaterRotate(pos.copy(), invref)\n",
    "print(time.time() - t)\n",
    "\n",
    "print(R,np.linalg.det(R))\n",
    "print(R @ R.T)\n",
    "print(R @ ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import VAEunet\n",
    "import utils\n",
    "net = VAEunet(channel_mult = (1, 2, 3, 4))\n",
    "temp = torch.rand((1, 1))\n",
    "print(\"\\n\".join(utils.model.model_structure(net)))\n",
    "image = torch.rand((1, 10, 4,25, 25))\n",
    "mu, nu, x = net(image, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import AFMGenDataset\n",
    "dts = AFMGenDataset(\"/Volumes/HEIU/data/ice_8_4A/ice_8_4A_train.hdf5\")\n",
    "name, box4a, box8a = dts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(box4a[...,0].nonzero()))\n",
    "print(len(box8a[...,0].nonzero()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.zeros(10)\n",
    "a[(0,1,2),] = 1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.functional import cdist2, sort, nms_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "u = np.random.rand(10000, 3)\n",
    "v = np.random.rand(10000, 3)\n",
    "t = time.time()\n",
    "for i in range(100):\n",
    "    out_n = cdist2(u)\n",
    "print(time.time() - t)\n",
    "u, v = torch.from_numpy(u), torch.from_numpy(v)\n",
    "t = time.time()\n",
    "for i in range(100):\n",
    "    out_t = torch.cdist(u, u, 2)\n",
    "print(time.time() - t)\n",
    "print(out_n, out_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sort(np.random.rand(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from utils.functional import nms_mask\n",
    "a = np.random.rand(1000, 3) * 1\n",
    "t = time.time()\n",
    "iu = np.triu_indices(a.shape[0])\n",
    "for i in range(100):\n",
    "    mask = nms_mask(a, 0.1)\n",
    "print(time.time() - t)\n",
    "# a = np.triu(np.where(a > 0.5, np.inf, a))\n",
    "# np.unravel_index(np.argpartition(a, 100 * 99 // 2, axis=None), a.shape)\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "def unravel_index(index, shape):\n",
    "    out = []\n",
    "    for dim in reversed(shape):\n",
    "        out.append(index % dim)\n",
    "        index = index // dim\n",
    "    return tuple(reversed(out))\n",
    "\n",
    "def argmatch(A: Tensor, B: Tensor, cutoff: float) -> tuple[Tensor]:\n",
    "    dis = torch.cdist(A, B)\n",
    "    dis = dis < cutoff\n",
    "    \n",
    "    \n",
    "    return out\n",
    "\n",
    "@torch.jit.script\n",
    "def nms_mask(pos: Tensor, cutoff: float) -> Tensor:\n",
    "    DIS = torch.cdist(pos, pos)\n",
    "    DIS = DIS < cutoff\n",
    "    DIS = (torch.triu(DIS, diagonal= 1)).float()\n",
    "    args = torch.ones(pos.shape[0], dtype = torch.bool, device = pos.device)\n",
    "    while True:\n",
    "        N = pos.shape[0]\n",
    "        restrain_tensor = DIS.sum(0)\n",
    "        restrain_tensor -= ((restrain_tensor != 0).float() @ DIS)\n",
    "        SELECT = restrain_tensor == 0\n",
    "        DIS = DIS[SELECT][:, SELECT]\n",
    "        pos = pos[SELECT]\n",
    "        args[args.clone()] = SELECT\n",
    "        if N == pos.shape[0]:\n",
    "            break\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "b = torch.from_numpy(a)\n",
    "t = time.time()\n",
    "for i in range(100):\n",
    "    out = nms(b, 0.1)\n",
    "print(time.time() - t)\n",
    "print(out.shape, mask.shape)\n",
    "print(out.sum(), mask.sum())\n",
    "pos = torch.cdist(b[out], b[out])\n",
    "pos = torch.triu(pos < 0.1, 1)\n",
    "print(pos.sum())\n",
    "# print(out.numpy()[:50])\n",
    "# print(a[mask][:50])\n",
    "print(np.allclose(out.numpy(), mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3666548728942871\n",
      "tensor([[100, 143, 156, 395, 336, 209, 350, 433, 100, 157,   4, 402,  73,  37,\n",
      "          47, 141, 237, 266, 132,  97, 354,   0, 736, 162, 187,  58,  77, 385,\n",
      "         142, 100, 185, 187, 156, 189, 259, 268, 163,   0, 802, 541, 829,   4,\n",
      "          28,  90, 471, 175, 220,  13,  29, 139, 159,  97,  51,  51, 649, 215,\n",
      "          60, 472,  24, 140, 215,  90, 118, 200, 664, 180,  60, 984,  93,  83,\n",
      "         381,  58,  40, 206, 592,  64, 237,  51, 235, 418,  22, 126, 215, 615,\n",
      "         163, 176,  88, 120, 329,  70, 911, 190, 101, 143, 403],\n",
      "        [  0,   1,   2,   3,   4,   5,   7,   8,   9,  10,  11,  12,  13,  15,\n",
      "          16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
      "          30,  31,  32,  33,  34,  36,  37,  38,  39,  40,  41,  42,  43,  44,\n",
      "          45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
      "          59,  60,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
      "          74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
      "          88,  89,  90,  91,  92,  93,  94,  96,  97,  98,  99]])\n",
      "torch.Size([78]) torch.Size([95])\n"
     ]
    }
   ],
   "source": [
    "def argmatch(pred: Tensor, targ: Tensor, cutoff: float) -> tuple[Tensor]:\n",
    "    dis = torch.cdist(targ, pred)\n",
    "    dis = (dis < cutoff).nonzero()\n",
    "    dis = dis[:, (1, 0)]\n",
    "    unique, idx, counts = torch.unique(dis[...,1], sorted=True, return_inverse=True, return_counts=True)\n",
    "    ind_sorted = torch.argsort(idx, stable=True)\n",
    "    cum_sum = counts.cumsum(0)\n",
    "    cum_sum = torch.cat((torch.tensor([0]), cum_sum[:-1]))\n",
    "    first_indicies = ind_sorted[cum_sum]\n",
    "    dis = dis[first_indicies]\n",
    "    return dis\n",
    "\n",
    "import torch\n",
    "b = torch.rand(1000, 3)\n",
    "c = torch.rand(100, 3)\n",
    "t = time.time()\n",
    "for i in range(1000):\n",
    "    reg = argmatch(b, c, 0.1)\n",
    "print(time.time() - t)\n",
    "reg = argmatch(b, c, 0.1).T\n",
    "print(reg)\n",
    "print(reg[0].unique().shape, reg[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
