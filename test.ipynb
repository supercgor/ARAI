{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "offset = 1\n",
    "select_num = 0\n",
    "upper = 4\n",
    "a = list(range(10))\n",
    "r = sample(range(upper), k=(select_num % upper))\n",
    "[i + offset for i in range(upper) for _ in range(select_num // upper + (i in r))]\n",
    "a[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def weighted_split(nums, ratio, mode = math.ceil):\n",
    "        if len(ratio) <= 1:\n",
    "            return nums,\n",
    "        else:\n",
    "            out = mode(nums * ratio[0]/sum(ratio))\n",
    "            return out, *weighted_split(nums - out, ratio = ratio[1:], mode = mode)\n",
    "\n",
    "weighted_split(100, (0.33,0.42,0.17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 999\n",
    "p = (0.3,0.3,0.3)\n",
    "print([a * i / sum(p) for i in p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.extend(i for i in range(10))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import indexGen\n",
    "import os\n",
    "path = \"/home/supercgor/gitfile/ARAI/datasets/data/HDA/afm\"\n",
    "a = indexGen(use_len= 5, out_len = 16, rand= True)\n",
    "for i in os.listdir(path):\n",
    "    if \"HDA_5\" in i:\n",
    "        print(a.get(f\"{path}/{i}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "epoch = 0\n",
    "pbar = tqdm(total = 100,desc = str(epoch), position = 0)\n",
    "for i in range(10):\n",
    "    pbar.update(1)\n",
    "    epoch += 1\n",
    "pbar.close()\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from network.NLayerNN import NLayerDiscriminator\n",
    "netA = NLayerDiscriminator(in_channels = 1)\n",
    "netB = NLayerDiscriminator(in_channels = 1)\n",
    "netA.requires_grad_(False)\n",
    "netB.requires_grad_(True)\n",
    "inp = torch.rand((1,1,128,128))\n",
    "x = netA(inp)\n",
    "x = netB(inp * x)\n",
    "netA.requires_grad_(True)\n",
    "netB.requires_grad_(False)\n",
    "x = netA(inp)\n",
    "x = netB(inp * x)\n",
    "x.backward()\n",
    "netB.requires_grad_(True)\n",
    "\n",
    "\n",
    "grads = []\n",
    "for param in netA.parameters():\n",
    "    if param.grad is None:\n",
    "        print(\"None\")\n",
    "        break\n",
    "    grads.append(param.grad.view(-1))\n",
    "else:\n",
    "    grads = torch.cat(grads)\n",
    "    print(grads.mean())\n",
    "\n",
    "grads = []\n",
    "for param in netB.parameters():\n",
    "    if param.grad is None:\n",
    "        print(\"None\")\n",
    "        break\n",
    "    grads.append(param.grad.view(-1))\n",
    "else:\n",
    "    grads = torch.cat(grads)\n",
    "    print(grads.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import Logger\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "a = Logger(\"/home/supercgor/gitfile/ARAI\", \"123.log\")\n",
    "top = tqdm(total= 100, desc=f\"TOP\", position=0, leave=True, unit='it')\n",
    "mid = tqdm(total= 50, desc=f\"MID\", position=1, leave=False, unit='it')\n",
    "bot = tqdm(total= 50, desc=f\"BOT\", position=2, leave=False, unit='it')\n",
    "for i in range(100):\n",
    "    for j in range(50):\n",
    "        time.sleep(0.2)\n",
    "        mid.update(1)\n",
    "    for j in range(50):\n",
    "        time.sleep(0.1)\n",
    "        bot.update(1)        \n",
    "    top.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(10000,2)\n",
    "b = np.random.rand(10, 10000) > 0.5\n",
    "b @ a / 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.unet3d_model import TransUNet3D\n",
    "from network.basic import basicParallel\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "preds.append(torch.load(\"/home/supercgor/gitfile/ARAI/datasets/data/exp/npy/9A_basel/HDA_3_-1_-1_1_1.npy\"))\n",
    "preds.append(torch.load(\"/home/supercgor/gitfile/ARAI/datasets/data/exp/npy/9A_basel/HDA_3_-1_-1_0_1.npy\"))\n",
    "preds = np.asarray(preds)\n",
    "preds = torch.from_numpy(preds)\n",
    "sp = tuple(preds.shape)\n",
    "sp = (*sp[:-1], sp[-1] // 4 , 4)\n",
    "preds = preds.reshape(sp)\n",
    "print(preds.shape)\n",
    "preds = torch.permute(preds, (0, 4, 1, 2, 3, 5))\n",
    "a = np.moveaxis(np.indices((32,32,9)), 0, -1)\n",
    "print(preds.shape)\n",
    "pos = (preds[...,:3] + a)\n",
    "pos = pos.reshape((*pos.shape[:2], -1, 3)) \n",
    "select = (preds[...,3] > 0).reshape(*pos.shape[:2], -1)\n",
    "print(pos.shape)\n",
    "print(select.shape)\n",
    "pos = pos.mul(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class a():\n",
    "    def __init__(self, b: OrderedDict):\n",
    "        self.b = b\n",
    "\n",
    "e = {\"O\": 1.4, \"H\": 1.5}\n",
    "c = OrderedDict(e)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import math\n",
    "_ = torch.manual_seed(123)\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "fid = FrechetInceptionDistance(feature=64).cuda()\n",
    "imgs_dist1 = torch.ones((20, 4, 32, 32), device=\"cuda\") * 255\n",
    "imgs_dist1 = imgs_dist1.to(dtype = torch.uint8)\n",
    "row = math.ceil(math.sqrt(imgs_dist1.shape[1]))\n",
    "imgs_dist1 = imgs_dist1.view(20,4, 1, 32, 32)\n",
    "imgs_dist1 = imgs_dist1.expand(-1, -1, 3, -1, -1)\n",
    "\n",
    "imgs_dist2 = torch.randn((20, 4, 32, 32), device=\"cuda\") * 255\n",
    "imgs_dist2 = imgs_dist2.to(dtype = torch.uint8)\n",
    "row = math.ceil(math.sqrt(imgs_dist2.shape[1]))\n",
    "imgs_dist2 = imgs_dist2.view(20,4, 1, 32, 32)\n",
    "imgs_dist2 = imgs_dist2.expand(-1, -1, 3, -1, -1)\n",
    "\n",
    "for i in imgs_dist1:\n",
    "    img = make_grid(i, nrow = row, padding= 0)\n",
    "    fid.update(i, real=True)\n",
    "\n",
    "for i in imgs_dist2:\n",
    "    img = make_grid(i, nrow = row, padding= 0)\n",
    "    fid.update(i, real=False)\n",
    "\n",
    "fid.compute()\n",
    "\n",
    "for i in imgs_dist1:\n",
    "    img = make_grid(i, nrow = row, padding= 0)\n",
    "    fid.update(i, real=True)\n",
    "\n",
    "for i in imgs_dist2:\n",
    "    img = make_grid(i, nrow = row, padding= 0)\n",
    "    fid.update(i, real=False)\n",
    "\n",
    "\n",
    "fid.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "predictions = torch.randn((16, 32, 32, 4, 8))\n",
    "batch, X, Y, Z, last = predictions.shape\n",
    "P = predictions[..., range(3,last,4)] > 0\n",
    "P = torch.permute(P, (0, 4, 3, 1, 2))  # X, Y, Z, C -> C, Z, H, W\n",
    "P = P.reshape((batch * 2 * Z, 1, X, Y))\n",
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset import read_pic\n",
    "from torchvision.utils import save_image\n",
    "imgs = read_pic(\"/home/supercgor/gitfile/ARAI/datasets/data/exp/afm/HDA_3_-1_-1_0_0\", [0,1,2,3])\n",
    "print(imgs.shape)\n",
    "imgs = imgs.view(1, 256, 256)\n",
    "save_image(imgs, \"./img.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analyze_data import Analyzer, Analyzer2\n",
    "from utils.loader import poscarLoader\n",
    "from config import get_config\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "a = torch.load(\"/home/supercgor/gitfile/ARAI/datasets/data/exp/npy/3A_with_more_data/HDA_3_-1_-1_0_1.npy\")\n",
    "b = torch.load(\"/home/supercgor/gitfile/ARAI/datasets/data/exp/npy/3A_with_more_data/HDA_3_-1_-1_0_1.npy\")\n",
    "a, b = torch.from_numpy(a), torch.from_numpy(b)\n",
    "B = Analyzer2(sort=True, threshold = 0)\n",
    "C = Analyzer(get_config())\n",
    "info = E = C(a,b)\n",
    "F = B(a,b)\n",
    "#print(OP)\n",
    "print(len(E['P_nms'][0][0]), len(set(E['TP_index_nms'][0][0][0].tolist())), len(E['P_nms'][0][1]), len(set(E['TP_index_nms'][0][1][0].tolist())))\n",
    "print(len(B.TP['O'][0]), len(B.FP['O'][0]), len(B.FN['O'][0]), len(B.TP['H'][0]), len(B.FP['H'][0]), len(B.FN['H'][0]))\n",
    "poscarLoader.pos2poscar(\"./test.poscar\",OrderedDict(O = B.P['O'][0], H = B.P['H'][0]))\n",
    "print(f\"{len(B.TP['O'][0])}\\n\",B.TP['O'][0], f\"\\n{len(B.TP['H'][0])}\\n\",B.TP[\"H\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = poscarLoader.pos2box({\"O\": B.P['O'][0], \"H\": B.P[\"H\"][0]}, (3, 25, 25), (4, 32, 32))\n",
    "IND = box[...,3].nonzero()\n",
    "print(IND.shape)\n",
    "print(box[IND[...,0],IND[...,1],IND[...,2],IND[...,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.stylegan2_pytorch.stylegan2_pytorch import Generator\n",
    "from network.basic import basicModel\n",
    "import torch\n",
    "class g(basicModel, Generator):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        Generator.__init__(self, *args, **kwargs)\n",
    "        basicModel.__init__(self)\n",
    "\n",
    "a = Generator(32,32)\n",
    "b = torch.rand(1,256)\n",
    "c = torch.randn(1,32,32,1)\n",
    "a(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.filters import filter3d\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import einops    \n",
    "\n",
    "w1 = torch.ones(3, 10, 3, 3, 3)\n",
    "w2 = torch.rand(1, 10)\n",
    "einops.einsum(w1,w2,\"O S P Q R, B S -> (B O) S P Q R\")\n",
    "a = einsum(\"O I P Q R, B S -> B O IS P Q R\", w1, w2)\n",
    "a[0,0]\n",
    "#einops.rearrange(img, \"b c 1 h w -> b c h w\").shape\n",
    "# f = torch.Tensor([1, 2, 1])\n",
    "# f = einsum(\"i,j,k->ijk\", f,f,f)\n",
    "# print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.styleGAN_cond_q3d.op import MapStyle3d\n",
    "from network.basic import structure\n",
    "import torch\n",
    "\n",
    "X = torch.randn(4, 32, 16, 128, 128)\n",
    "Y = torch.randn(4, 32, 16, 64, 64)\n",
    "Z = torch.randn(4, 64, 16, 32, 32)\n",
    "R = torch.randn(4, 128, 8, 16, 16)\n",
    "S = torch.randn(4, 256, 4, 8, 8)\n",
    "\n",
    "a = MapStyle3d(512)\n",
    "a(X)\n",
    "a(Y)\n",
    "a(Z)\n",
    "a(R)\n",
    "a(S)\n",
    "structure(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from network.unet3d_model import UNet3D\n",
    "a = UNet3D()\n",
    "x = torch.randn(4, 1, 16, 128, 128)\n",
    "x = x[:,:,0,0,0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 32, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# 在target 處的 confidence + 上 0.1的sigma 再放進去discri\n",
    "import torch\n",
    "from network.styleGAN_cond_q3d import StyleGAN3D\n",
    "from network.fea_Unet3d import UNet3D\n",
    "from network.basic import structure\n",
    "a = StyleGAN3D().cuda()\n",
    "b = UNet3D().cuda()\n",
    "b.requires_grad_(False)\n",
    "a.requires_grad_(False)\n",
    "x = torch.randn((2, 1, 16, 128, 128), device = \"cuda\")\n",
    "x, f = b(x)\n",
    "print(x.shape)\n",
    "noise = torch.randn((2, 16, 128, 128, 1), device = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 32, 4, 4]) torch.Size([2, 32, 32, 4, 4])\n",
      "torch.Size([2, 32, 32, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "import einops\n",
    "result = a(f, noise)\n",
    "result = einops.rearrange(result, \"B C Z X Y -> B X Y Z C\").contiguous()\n",
    "print(result.shape, x.shape)\n",
    "result = torch.concatenate([x, result], dim = -1)\n",
    "print(result.shape)\n",
    "loss = result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*map(lambda x: x.shape, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "a = torch.randn(2,16)\n",
    "b = torch.randn(512,16)\n",
    "F.linear(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import einsum\n",
    "k = torch.Tensor([1,2,1])\n",
    "einsum(\"i, j, k -> ijk\", k,k,k)[None,...].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
